{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJ7Nk2CSb3ZjCo9QxwhicL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this notebook, you will implement:\n","\n","* Create tensors from different data sources like Python lists and NumPy arrays.\n","\n","* Reshape and manipulate tensor dimensions to prepare data for model inputs.\n","\n","* Use indexing and slicing techniques to access and filter specific parts of your data.\n","\n","* Perform the mathematical and logical operations that form the basis of all neural network computations.\n"],"metadata":{"id":"3_YNRVcGBQU_"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"OwHTmJCnAZLg","executionInfo":{"status":"ok","timestamp":1766356097636,"user_tz":480,"elapsed":9410,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}}},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["x = torch.tensor([1,2,3]) # from python list to tensor\n","print(\"From python lists :\",x)\n","print(\"Tensor :\", x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkLIYRJLBuOc","executionInfo":{"status":"ok","timestamp":1766356131776,"user_tz":480,"elapsed":70,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"8c050a04-4cf4-4afb-89a2-17500631bf5d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["From python lists : tensor([1, 2, 3])\n","Tensor : torch.int64\n"]}]},{"cell_type":"code","source":["x_numpy = np.array([[1,2,3],[4,5,6]])\n","x_tensor_from_numpy = torch.from_numpy(x_numpy)\n","print(\"tensor from numy :\\n\\n\",x_tensor_from_numpy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNzJabsoB58M","executionInfo":{"status":"ok","timestamp":1766356250102,"user_tz":480,"elapsed":4,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"3fe21083-322f-45d3-bda3-af450804da6d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor from numy :\n","\n"," tensor([[1, 2, 3],\n","        [4, 5, 6]])\n"]}]},{"cell_type":"code","source":["#now from pandas dataframe , pandas is the data manupulation library , which use dataframe to store the data into the format of csv and spreadsheet\n","# there is not direct way to convert the pandas dataframe to tensor , so we convert the dataframe to numpy with .values() and then create the tensor\n","# from the numpy array\n","!gdown --fuzzy https://drive.google.com/file/d/1sDyPpdUUSiE1wIWajkBApkNZLwVwf4hi/view?usp=drive_link"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBqHrY4jCUJ2","executionInfo":{"status":"ok","timestamp":1766356554882,"user_tz":480,"elapsed":2214,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"456bff0e-3e94-44e6-f9f8-36961a9e13ce"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1sDyPpdUUSiE1wIWajkBApkNZLwVwf4hi\n","To: /content/data.csv\n","\r  0% 0.00/69.0 [00:00<?, ?B/s]\r100% 69.0/69.0 [00:00<00:00, 210kB/s]\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"data.csv\")\n","\n","numpy_df = df.values\n","#convert this to tensor\n","tensor_df = torch.tensor(numpy_df)\n","print(\"pandas dataframe :\\n\", df)\n","print(\"tensor:\\n\",tensor_df)\n","print(\"tensor type:\\n\",tensor_df.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44GTcnQwDfP7","executionInfo":{"status":"ok","timestamp":1766356906754,"user_tz":480,"elapsed":241,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"b567ea3f-567c-4e21-c16b-ed297206b655"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["pandas dataframe :\n","    distance_miles  delivery_time_minutes\n","0            1.60                   7.22\n","1           13.09                  32.41\n","2            6.97                  17.47\n","tensor:\n"," tensor([[ 1.6000,  7.2200],\n","        [13.0900, 32.4100],\n","        [ 6.9700, 17.4700]], dtype=torch.float64)\n","tensor type:\n"," torch.float64\n"]}]},{"cell_type":"code","source":["zeros = torch.ones(2,3)\n","print(zeros)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyrIYdH2Ey3y","executionInfo":{"status":"ok","timestamp":1766356958728,"user_tz":480,"elapsed":12,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"7b182f4a-b4f6-4482-da64-1eda74c692fd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n"]}]},{"cell_type":"code","source":["range_val = torch.arange(0,10,step=2)\n","print(range_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-SWbgzSFBaL","executionInfo":{"status":"ok","timestamp":1766357032269,"user_tz":480,"elapsed":15,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"cfc7625e-3ece-4f97-f666-c61878bb5bd5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 2, 4, 6, 8])\n"]}]},{"cell_type":"code","source":["y = torch.tensor([[1.,2.,3.],[4.,5.,6]])\n","print(\"Original Tensor\\n\",y)\n","print(\"shape :\",y.shape)\n","y = y.unsqueeze(0)\n","print(\"shape :\",y.shape)\n","print(\"\\nTENSOR WITH ADDED DIMENSION AT INDEX 0:\\n\\n\", y)\n","\n","y = y.squeeze(0)\n","print(\"back to original :\\n\",y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whqqRU7nFRvh","executionInfo":{"status":"ok","timestamp":1766357575007,"user_tz":480,"elapsed":37,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"29467ac1-7725-4e45-aaec-ae26bebf5353"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tensor\n"," tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","shape : torch.Size([2, 3])\n","shape : torch.Size([1, 2, 3])\n","\n","TENSOR WITH ADDED DIMENSION AT INDEX 0:\n","\n"," tensor([[[1., 2., 3.],\n","         [4., 5., 6.]]])\n","back to original :\n"," tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n"]}]},{"cell_type":"code","source":["z = torch.ones(1,2,3)\n","print(z.shape)\n","z = z.transpose(1,2)\n","print(z.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHzPkmdoGu8h","executionInfo":{"status":"ok","timestamp":1766358100226,"user_tz":480,"elapsed":5,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"699d7007-8d4c-4e0e-e679-1f1326749e23"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 3])\n","torch.Size([1, 3, 2])\n"]}]},{"cell_type":"code","source":["z1 = torch.zeros(1,2,3)\n","z1 = z1.transpose(1,2)\n","z_final = torch.cat((z,z1),dim=2)\n","print(z_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTuU4c8pHrvU","executionInfo":{"status":"ok","timestamp":1766358230263,"user_tz":480,"elapsed":5,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"bd0be48d-c2aa-4531-c1c3-76307994abda"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1., 1., 0., 0.],\n","         [1., 1., 0., 0.],\n","         [1., 1., 0., 0.]]])\n"]}]},{"cell_type":"code","source":["x = torch.tensor([\n","    [1, 2, 3, 4],\n","    [5, 6, 7, 8],\n","    [9, 10, 11, 12]\n","])\n","print(\"original tensor: \\n\",x)\n","print(\"-\"*55)\n","element_r1c2 = x[1][2]\n","print(\"row 1 and col 2 : \",element_r1c2)\n","print(\"-\"*55)\n","row_2 = x[1]\n","print(\"row 2 : \",row_2)\n","print(\"-\"*55)\n","row_1_2 = x[0:2]\n","print(\"1st two rows :\",row_1_2)\n","print(\"-\"*55)\n","col_3_row_all = x[:,2]\n","print(\"third col , all rows :\",col_3_row_all)\n","every_other_col = x[:,::2]\n","print(every_other_col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzfsT9lSJkIN","executionInfo":{"status":"ok","timestamp":1766358891738,"user_tz":480,"elapsed":65,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"4bd76046-0332-476e-c4ad-78bbf352938c"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["original tensor: \n"," tensor([[ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12]])\n","-------------------------------------------------------\n","row 1 and col 2 :  tensor(7)\n","-------------------------------------------------------\n","row 2 :  tensor([5, 6, 7, 8])\n","-------------------------------------------------------\n","1st two rows : tensor([[1, 2, 3, 4],\n","        [5, 6, 7, 8]])\n","-------------------------------------------------------\n","third col , all rows : tensor([ 3,  7, 11])\n","tensor([[ 1,  3],\n","        [ 5,  7],\n","        [ 9, 11]])\n"]}]},{"cell_type":"code","source":["#practice block\n","base_tensor = torch.tensor([\n","    [1,2,3,4],\n","    [5,6,7,8],\n","    [9,10,11,12]\n","])"],"metadata":{"id":"-B9lHw-qKW6D","executionInfo":{"status":"ok","timestamp":1766359231272,"user_tz":480,"elapsed":42,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["#first row\n","base_tensor[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EshL44y_NuqS","executionInfo":{"status":"ok","timestamp":1766359281249,"user_tz":480,"elapsed":7,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"1128b635-ea58-415a-d474-f5f8f84a0290"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4])"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["base_tensor[1:,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ-6cVM9N63k","executionInfo":{"status":"ok","timestamp":1766359518185,"user_tz":480,"elapsed":45,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"7c3dfaf5-5dd8-4790-d58c-498a0ecca671"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12]])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["base_tensor[:2,1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MaAX3HGAO0tE","executionInfo":{"status":"ok","timestamp":1766359654215,"user_tz":480,"elapsed":58,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"37a198ef-1ba8-44ec-dde3-c0522a6e48a5"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2, 3, 4],\n","        [6, 7, 8]])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["base_tensor[:,::2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEu894YHPV6R","executionInfo":{"status":"ok","timestamp":1766359677174,"user_tz":480,"elapsed":19,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"86d446ad-66ab-46cc-d6b7-0ec66c6f23cd"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  3],\n","        [ 5,  7],\n","        [ 9, 11]])"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["base_tensor[:,2:3].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKV7mrRlPbhg","executionInfo":{"status":"ok","timestamp":1766360010677,"user_tz":480,"elapsed":34,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"45d381b1-e7d2-4a50-b010-b532e0a1c0a4"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 1])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["base_tensor[1,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqnXSIZMQIHI","executionInfo":{"status":"ok","timestamp":1766360103446,"user_tz":480,"elapsed":13,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"e7241844-8156-4174-c0ae-7a4f6341335d"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5, 6, 7, 8])"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["## 5 - Optional Exercises\n","\n","You've now covered the essential tools for working with tensors in PyTorch. Theory provides the map, but hands-on practice is what builds true confidence and skill. The following optional exercises are your opportunity to apply what you have learned to practical scenarios, from analyzing sales data to engineering new features for a machine learning model. This is where the concepts truly come to life, so dive in and put your new knowledge to the test!\n","\n","### Exercise 1: Analyzing Monthly Sales Data\n","\n","You're a data analyst at an e-commerce company. You've been given a tensor representing the monthly sales of three different products over a period of four months. Your task is to extract meaningful insights from this data.\n","\n","The tensor `sales_data` is structured as follows:\n","\n","* **Rows** represent the **products** (Product A, Product B, Product C).\n","\n","* **Columns** represent the **months** (Jan, Feb, Mar, Apr).\n","\n","**Your goals are**:\n","\n","1. Calculate the total sales for **Product B** (the second row).\n","2. Identify which months had sales **greater than 130** for **Product C** (the third row) using boolean masking.\n","3. Extract the sales data for all products for the months of **Feb and Mar** (the middle two columns).\n","\n","<br>\n","\n","<details>\n","<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n","\n","```python\n","### START CODE HERE ###\n","\n","# 1. Calculate total sales for Product B.\n","total_sales_product_b = sales_data[1].sum()\n","\n","# 2. Find months where sales for Product C were > 130.\n","high_sales_mask_product_c = sales_data[2] > 130\n","\n","# 3. Get sales for Feb and Mar for all products.\n","sales_feb_mar = sales_data[:, 1:3]\n","\n","### END CODE HERE ###\n","```"],"metadata":{"id":"5AICy7S1UTF9"}},{"cell_type":"code","source":["# Sales data for 3 products over 4 months\n","sales_data = torch.tensor([[100, 120, 130, 110],   # Product A\n","                           [ 90,  95, 105, 125],   # Product B\n","                           [140, 115, 120, 150]    # Product C\n","                          ], dtype=torch.float32)\n","\n","print(\"ORIGINAL SALES DATA:\\n\\n\", sales_data)\n","print(\"-\" * 45)\n","\n","### START CODE HERE ###\n","\n","# 1. Calculate total sales for Product B.\n","# we need to fetch the row b , second row and add that row\n","\n","total_sales_product_b =  sales_data[1,:].sum()\n","\n","# 2. Find months where sales for Product C were > 130.\n","high_sales_mask_product_c = sales_data[2,:] > 130\n","\n","# 3. Get sales for Feb and Mar for all products.\n","sales_feb_mar = sales_data[:,1:3]\n","\n","### END CODE HERE ###\n","\n","print(\"\\nTotal Sales for Product B:                   \", total_sales_product_b)\n","print(\"\\nMonths with >130 Sales for Product C (Mask): \", high_sales_mask_product_c)\n","print(\"\\nSales for Feb & Mar:\\n\\n\", sales_feb_mar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KWTFjnqRBdi","executionInfo":{"status":"ok","timestamp":1766360965088,"user_tz":480,"elapsed":38,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"4d74cd08-0dfe-4261-f71d-78dadd00df99"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL SALES DATA:\n","\n"," tensor([[100., 120., 130., 110.],\n","        [ 90.,  95., 105., 125.],\n","        [140., 115., 120., 150.]])\n","---------------------------------------------\n","\n","Total Sales for Product B:                    tensor(415.)\n","\n","Months with >130 Sales for Product C (Mask):  tensor([ True, False, False,  True])\n","\n","Sales for Feb & Mar:\n","\n"," tensor([[120., 130.],\n","        [ 95., 105.],\n","        [115., 120.]])\n"]}]},{"cell_type":"markdown","source":["#### Expected Output:\n","\n","```\n","Total Sales for Product B:\t\t\t tensor(415.)\n","\n","Months with >130 Sales for Product C (Mask):\t tensor([ True, False, False,  True])\n","\n","Sales for Feb & Mar:\n","\n"," tensor([[120., 130.],\n","        [ 95., 105.],\n","        [115., 120.]])\n","```"],"metadata":{"id":"8SjEO1TYUaBK"}},{"cell_type":"markdown","source":["### Exercise 2: Image Batch Transformation\n","\n","You're working on a computer vision model and have a batch of 4 grayscale images, each of size 3x3 pixels. The data is currently in a tensor with the shape `[4, 3, 3]`, which represents `[batch_size, height, width]`.\n","\n","For processing with certain deep learning frameworks, you need to transform this data into the `[batch_size, channels, height, width]` format. Since the images are grayscale, **you'll need to**:\n","\n","1. Add a new dimension of size 1 at index 1 to represent the color channel.\n","2. After adding the channel, you realize the model expects the shape `[batch_size, height, width, channels]`. Transpose the tensor to swap the channel dimension with the last dimension.\n","\n","<br>\n","\n","<details>\n","<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n","\n","```python\n","### START CODE HERE ###\n","\n","# 1. Add a channel dimension at index 1.\n","image_batch_with_channel = image_batch.unsqueeze(1)\n","\n","# 2. Transpose the tensor to move the channel dimension to the end.\n","# Swap dimension 1 (channels) with dimension 3 (the last one).\n","image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n","\n","### END CODE HERE ###\n","```"],"metadata":{"id":"l_-2Yp20VRhi"}},{"cell_type":"code","source":["# A batch of 4 grayscale images, each 3x3\n","image_batch = torch.rand(4, 3, 3)\n","\n","print(\"ORIGINAL BATCH SHAPE:\", image_batch.shape)\n","print(\"-\" * 45)\n","\n","### START CODE HERE ###\n","\n","# 1. Add a channel dimension at index 1.\n","image_batch_with_channel = image_batch.unsqueeze(1)\n","\n","# 2. Transpose the tensor to move the channel dimension to the end.\n","# Swap dimension 1 (channels) with dimension 3 (the last one).\n","# we will need to do two transpose\n","temp = image_batch_with_channel.transpose(1,2)\n","print(temp.shape)\n","image_batch_transposed = temp.transpose(2,3)\n","\n","### END CODE HERE ###\n","\n","\n","print(\"\\nSHAPE AFTER UNSQUEEZE:\", image_batch_with_channel.shape)\n","print(\"SHAPE AFTER TRANSPOSE:\", image_batch_transposed.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khLEY8QCUV9E","executionInfo":{"status":"ok","timestamp":1766361234696,"user_tz":480,"elapsed":45,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"500e6e19-55a1-4579-e1bb-f5e62386fd0e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL BATCH SHAPE: torch.Size([4, 3, 3])\n","---------------------------------------------\n","torch.Size([4, 3, 1, 3])\n","\n","SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n","SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n"]}]},{"cell_type":"markdown","source":["#### Expected Output:\n","\n","```\n","SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n","SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n","```"],"metadata":{"id":"BmiiHMseVcCV"}},{"cell_type":"markdown","source":["### Exercise 3: Combining and Weighting Sensor Data\n","\n","You're building an environment monitoring system that uses two sensors: one for temperature and one for humidity. You receive data from these sensors as two separate 1D tensors.\n","\n","**Your task is to**:\n","\n","1. **Concatenate** the two tensors into a single `2x5` tensor, where the first row is temperature data and the second is humidity data.\n","2. Create a `weights` tensor `torch.tensor([0.6, 0.4])`.\n","3. Use **broadcasting and element-wise multiplication** to apply these weights to the combined sensor data. The temperature data should be multiplied by 0.6 and the humidity data by 0.4.\n","4. Finally, calculate the **weighted average** for each time step by **summing** the weighted values along `dim=0` and **dividing** by the sum of the weights.\n","\n","<br>\n","\n","<details>\n","<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n","\n","```python\n","### START CODE HERE ###\n","\n","# 1. Concatenate the two tensors.\n","# Note: You need to unsqueeze them first to stack them vertically.\n","combined_data = torch.cat((temperature.unsqueeze(0), humidity.unsqueeze(0)), dim=0)\n","\n","# 2. Create the weights tensor.\n","weights = torch.tensor([0.6, 0.4])\n","\n","# 3. Apply weights using broadcasting.\n","# You need to reshape weights to [2, 1] to broadcast across columns.\n","weighted_data = combined_data * weights.unsqueeze(1)\n","\n","# 4. Calculate the weighted average for each time step.\n","#    (A true average = weighted sum / sum of weights)\n","weighted_sum = torch.sum(weighted_data, dim=0)\n","weighted_average = weighted_sum / torch.sum(weights)\n","\n","### END CODE HERE ###\n","```"],"metadata":{"id":"TcRSqDzRYqTb"}},{"cell_type":"code","source":["# Sensor readings (5 time steps)\n","temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n","humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n","\n","print(\"TEMPERATURE DATA: \", temperature)\n","print(\"HUMIDITY DATA:    \", humidity)\n","print(\"-\" * 45)\n","\n","### START CODE HERE ###\n","\n","# 1. Concatenate the two tensors.\n","# Note: You need to unsqueeze them first to stack them vertically.\n","combined_data = torch.cat((temperature.unsqueeze(0),humidity.unsqueeze(0)),dim = 0)\n","\n","# 2. Create the weights tensor.\n","weights = torch.tensor([0.6,0.4])\n","\n","# 3. Apply weights using broadcasting.\n","# You need to reshape weights to [2, 1] to broadcast across columns.\n","weighted_data = combined_data * weights.unsqueeze(1)\n","\n","# 4. Calculate the weighted average for each time step.\n","#    (A true average = weighted sum / sum of weights)\n","weighted_sum = torch.sum(weighted_data,dim=0)\n","weighted_average = weighted_sum / torch.sum(weights)\n","\n","### END CODE HERE ###\n","\n","print(\"\\nCOMBINED DATA (2x5):\\n\\n\", combined_data)\n","print(\"\\nWEIGHTED DATA:\\n\\n\", weighted_data)\n","print(\"\\nWEIGHTED AVERAGE:\", weighted_average)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inpELeWZVXxb","executionInfo":{"status":"ok","timestamp":1766362121068,"user_tz":480,"elapsed":50,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"a02d2068-f6e4-4c84-ed72-c97164fc26c7"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["TEMPERATURE DATA:  tensor([22.5000, 23.1000, 21.9000, 22.8000, 23.5000])\n","HUMIDITY DATA:     tensor([55.2000, 56.4000, 54.8000, 57.1000, 56.8000])\n","---------------------------------------------\n","\n","COMBINED DATA (2x5):\n","\n"," tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n","        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n","\n","WEIGHTED DATA:\n","\n"," tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n","        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n","\n","WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n"]}]},{"cell_type":"markdown","source":["#### Expected Output:\n","\n","```\n","COMBINED DATA (2x5):\n","\n"," tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n","        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n","\n","WEIGHTED DATA:\n","\n"," tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n","        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n","\n","WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n","```"],"metadata":{"id":"6w1V8MhFY2BC"}},{"cell_type":"markdown","source":["### Exercise 4: Feature Engineering for Taxi Fares\n","\n","You are working with a dataset of taxi trips. You have a tensor, `trip_data`, where each row is a trip and the columns represent **[distance (km), hour_of_day (24h)]**.\n","\n","**Your goal** is to engineer a new binary feature called `is_rush_hour_long_trip`. This feature should be `True` (or `1`) only if a trip meets **both** of the following criteria:\n","\n","* It's a **long trip** (distance > 10 km).\n","* It occurs during a **rush hour** (8-10 AM or 5-7 PM, i.e., `[8, 10)` or `[17, 19)`).\n","\n","To achieve this, you will need to:\n","\n","1. **Slice** the `trip_data` tensor to isolate the `distance` and `hour` columns.\n","2. Use **logical and comparison operators** to create boolean masks for each condition (long trip, morning rush, evening rush).\n","3. Combine these masks to create the final `is_rush_hour_long_trip` feature.\n","4. **Reshape** this new 1D feature tensor into a 2D column vector and convert its data type to float so it can be combined with the original data.\n","\n","<br>\n","\n","<details>\n","<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n","\n","```python\n","### START CODE HERE ###\n","\n","# 1. Slice the main tensor to get 1D tensors for each feature.\n","distances = trip_data[:, 0]\n","hours = trip_data[:, 1]\n","\n","# 2. Create boolean masks for each condition.\n","is_long_trip = distances > 10.0\n","is_morning_rush = (hours >= 8.0) & (hours < 10.0)\n","is_evening_rush = (hours >= 17.0) & (hours < 19.0)\n","\n","# 3. Combine masks to identify rush hour long trips.\n","# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n","is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n","\n","# 4. Reshape the new feature into a column vector and cast to float.\n","new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n","\n","### END CODE HERE ###\n","```"],"metadata":{"id":"IrCn8Jv-ZEB6"}},{"cell_type":"code","source":["# Data for 8 taxi trips: [distance, hour_of_day]\n","trip_data = torch.tensor([\n","    [5.3, 7],   # Not rush hour, not long\n","    [12.1, 9],  # Morning rush, long trip -> RUSH HOUR LONG\n","    [15.5, 13], # Not rush hour, long trip\n","    [6.7, 18],  # Evening rush, not long\n","    [2.4, 20],  # Not rush hour, not long\n","    [11.8, 17], # Evening rush, long trip -> RUSH HOUR LONG\n","    [9.0, 9],   # Morning rush, not long\n","    [14.2, 8]   # Morning rush, long trip -> RUSH HOUR LONG\n","], dtype=torch.float32)\n","\n","\n","print(\"ORIGINAL TRIP DATA (Distance, Hour):\\n\\n\", trip_data)\n","print(\"-\" * 55)\n","\n","\n","### START CODE HERE ###\n","\n","# 1. Slice the main tensor to get 1D tensors for each feature.\n","distances = trip_data[:, 0]\n","hours = trip_data[:, 1]\n","\n","# 2. Create boolean masks for each condition.\n","is_long_trip = distances > 10.0\n","is_morning_rush = (hours >= 8.0) & (hours < 10.0)\n","is_evening_rush = (hours >= 17.0) & (hours < 19.0)\n","\n","# 3. Combine masks to identify rush hour long trips.\n","# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n","is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n","\n","# 4. Reshape the new feature into a column vector and cast to float.\n","new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n","\n","### END CODE HERE ###\n","\n","print(\"\\n'IS RUSH HOUR LONG TRIP' MASK: \", is_rush_hour_long_trip_mask)\n","print(\"\\nNEW FEATURE COLUMN (Reshaped):\\n\\n\", new_feature_col)\n","\n","# You can now concatenate this new feature to the original data\n","enhanced_trip_data = torch.cat((trip_data, new_feature_col), dim=1)\n","print(\"\\nENHANCED DATA (with new feature at the end):\\n\\n\", enhanced_trip_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkABwmiHY0NA","executionInfo":{"status":"ok","timestamp":1766362218606,"user_tz":480,"elapsed":51,"user":{"displayName":"Poojan Patel","userId":"02020528048548570602"}},"outputId":"0ac0492c-9eb6-4f5d-cd88-8cdfa5929d09"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL TRIP DATA (Distance, Hour):\n","\n"," tensor([[ 5.3000,  7.0000],\n","        [12.1000,  9.0000],\n","        [15.5000, 13.0000],\n","        [ 6.7000, 18.0000],\n","        [ 2.4000, 20.0000],\n","        [11.8000, 17.0000],\n","        [ 9.0000,  9.0000],\n","        [14.2000,  8.0000]])\n","-------------------------------------------------------\n","\n","'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n","\n","NEW FEATURE COLUMN (Reshaped):\n","\n"," tensor([[0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.]])\n","\n","ENHANCED DATA (with new feature at the end):\n","\n"," tensor([[ 5.3000,  7.0000,  0.0000],\n","        [12.1000,  9.0000,  1.0000],\n","        [15.5000, 13.0000,  0.0000],\n","        [ 6.7000, 18.0000,  0.0000],\n","        [ 2.4000, 20.0000,  0.0000],\n","        [11.8000, 17.0000,  1.0000],\n","        [ 9.0000,  9.0000,  0.0000],\n","        [14.2000,  8.0000,  1.0000]])\n"]}]},{"cell_type":"markdown","source":["#### Expected Output:\n","\n","```\n","'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n","\n","NEW FEATURE COLUMN (Reshaped):\n","\n"," tensor([[0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.]])\n","\n","ENHANCED DATA (with new feature at the end):\n","\n"," tensor([[ 5.3000,  7.0000,  0.0000],\n","        [12.1000,  9.0000,  1.0000],\n","        [15.5000, 13.0000,  0.0000],\n","        [ 6.7000, 18.0000,  0.0000],\n","        [ 2.4000, 20.0000,  0.0000],\n","        [11.8000, 17.0000,  1.0000],\n","        [ 9.0000,  9.0000,  0.0000],\n","        [14.2000,  8.0000,  1.0000]])\n","```        "],"metadata":{"id":"m4gyAJGbZMHE"}},{"cell_type":"code","source":[],"metadata":{"id":"oFd3NQYcZH-4"},"execution_count":null,"outputs":[]}]}